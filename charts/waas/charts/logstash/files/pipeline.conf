input {
    http {
        host => "0.0.0.0"
        port => {{ .Values.global.logstash.serviceTargetPort | default 2020 }}
        id => "from_fbit"
        codec => "json"
    {{- with .Values.tls.server }}
      {{- if eq .enabled true }}
        ssl_enabled => true
        ssl_certificate => {{ .certificate | quote }}
        ssl_key => {{ .key | quote }}
        {{- if eq .clientAuth true }}
        ssl_client_authentication => "required"
        ssl_certificate_authorities => [{{ .ca | quote }}]
        {{- else }}
        ssl_verify_mode => "none"
        {{- end}}
      {{- else }}
        ssl => false
      {{- end }}
    {{- end }}
    }
}
filter {
    # fluentbit - according to fluent-bit-tutorials
    date {
        # get fluentbit date and save as 'fluentbit_ts'
        match => [ "date", "UNIX" ]
        target => "fluentbit_ts"
    }
    mutate {
        # use @timestamp to set the logstash arrival time. keep @timestamp as default
        copy => ["@timestamp", "logstash_ts"]
        # fluentbit sends the log entry under 'log' and not 'message'
        rename => ["log", "message"]
    }
    if [message] == "" {
        ruby {
            code => "logger.info('message is empty')"
        }
        drop { }
    }
    mutate {
        remove_field => ["log","agent","input","tags","host","ecs","@version", "headers", "date"]
    }
    # forensics log entry handling
    if [logtype] == "Forensics" {
        json {
            source => "message"
            target => "messagejson"
        }
        if [messagejson][events] {
            #split the message to events
            split {
                field => "[messagejson][events]"
                remove_field => ["@version"]
            }
        }
        ruby {
            #move all data from events object to messagejson
            code => '
                ev_path = "[messagejson][events]"
                if event.get(ev_path).is_a? Hash
                    event.get(ev_path).each { |k, v|
                        event.set("[messagejson][#{k}]", v)
                    }
                    event.remove(ev_path)
                end
            '
        }
        ruby {
            code => '
                if event.get("messagejson")
                    skip = false
                    event.get("messagejson").each {|k, v|
                        if k == "actorXffHeader" || k == "actorXffIp"
                            if v == "-" || v == ""
                              skip = true
                            end
                        end
                        if skip == false
                            event.set(k, v)
                        else
                            skip = false
                        end
                    }
                    ################################# multi profile support ##############################
                    # get protection id and profile name from protection id
                    protectionId = event.get("policyProtectionId")
                    unless protectionId .nil?
                        protectionIds = protectionId.split("@",-1)
                        if protectionIds.length() > 1
                            selector = event.get("profileName")
                            event.set("waas_profile_orig", selector)
                            event.set("waas_config_selector", selector)
                            event.set("waas_protection_orig", protectionId)
                            event.set("multi_profile_mode", "true")

                            event.set("policyProtectionId", protectionIds[0])
                            event.set("profileName", protectionIds[1])
                        end
                    end
                    # get actual policy name from classifier
                    cls = event.get("policyClsId")
                    unless cls.nil?
                        classifierIds = cls.split("@", -1)
                        if classifierIds.length() > 1
                            event.set("waas_policy_orig", event.get("policyName"))
                            event.set("waas_classifier_orig", cls)
                            event.set("policyClsId", classifierIds[0])
                            event.set("policyName", classifierIds[1])
                        end
                    end
                else
                    event.set("pipline_error","missing messagejson in forensics")
                end
            '
        }
        ruby {
            # calculate translation key separately from other code to avoid errors effecting this code
            code => '
                if event.get("messagejson")
                    ################################# end of multi profile support ##############################
                    eid = event.get("eventId")
                    trnsl_key = event.get("eventModule") + "-" + eid
                    # The eventSignature in Custom Rules events are coming from the user, therefore we cant use them as part of our translation_key
                    # Same goes with Pattern Groups - the user decide their names so we can not use them.
                    # For jwt the eventSignature is set as the enum declared by a 3rd party lib used by Envoy so its not relevant here.
                    esig = event.get("eventSignature")
                    ignore_esig = ["by_custom_rules", "by_pattern_groups", "by_jwt", "by_jwt_missing", "by_response_tracking", "by_response_tracking_rate_limit"].include? eid
                    if esig != nil && !ignore_esig
                        trnsl_key += "-" + esig
                    end
                    event.set("translation_key", trnsl_key)
                end
            '
        }
        date {
            # dateTime is the time set by the enforcer
            # enforcer event time will be saved in the @timestamp field.
            match => [ "dateTime" ,"ISO8601" ]
        }
        translate {
            source => "translation_key"
            target => "translation"
            dictionary_path => "/enrich-internal/translation_internal.json"
            add_field => { "translation_source" => "internal"}
        }
        translate {
            source => "translation_key"
            target => "translation"
            dictionary_path => "/enrich/translation.json"
            override => "false"
            add_field => { "translation_source" => "external"}
        }
        # ruby {
        #     # debug translate
        #     code => '
        #         logger.info("translate debug", "key" => event.get("translation_key"), "translation" => event.get("translation"))
        #         '
        # }
        json {
            source => "translation"
            target => "translationjson"
        }
        ruby {
            code => '
                if event.get("translationjson")
                    event.get("translationjson").each {|k, v|
                        event.set(k, v)
                    }
                end
            '
        }
        mutate {
            #TODO remove_field => ["waas_profile_orig", "waas_protection_orig", "waas_classifier_orig", "waas_policy_orig"]
            #TODO remove_field => ["translation_source"]
            remove_field => ["messagejson","message","translation_key","translation","translationjson", "dateTime"]
            rename=> {"profileName" => "waas_profile"}
            rename=> {"profileTag" => "waas_tag"}
        }
    # acccess log entry handling
    } else if [logtype] == "Access" {
        json {
            source => "message"
            target => "messagejson"
        }
        ruby {
            code => '
                if event.get("messagejson")
                    skip = false
                    event.get("messagejson").each {|k, v|
                        if v == "-"
                            if k == "bytes_recv" || k == "bytes_sent" || k == "duration" || k == "resp_time" || k == "resp_tx_duration" || k == "resp_duration"
                                v = 0
                            end
                        end
                        # fields added to access log by enforcer:
                        if k == "user_ip_header" || k == "user_ip_value" || k == "host_name" || k == "policy_hash" || k == "policy_name" || k == "classifier_name"
                            # trim leading and trailing double quotes (if exist)
                            unless v.nil?
                              if v.start_with?("\"")
                                    v = v[1..-2]
                              end
                            end
                            if v == "-" || v == ""
                                # dont pass the empty field to elastic
                                skip = true
                            end
                        end
                        if skip == false
                          event.set(k, v)
                        else
                          skip = false
                        end
                    }
                    ################################# multi profile support ##############################
                    # get classifier
                    cls = event.get("classifier_name")
                    unless cls.nil?
                        # split to classifier id and policy id
                        clsids = cls.split("@", -1)
                        if clsids.length() > 1
                            event.set("waas_classifier_orig", cls)
                            event.set("waas_policy_orig", event.get("policy_name"))
                            event.set("multi_profile_mode", "true")

                            event.set("classifier_name", clsids[0])
                            event.set("policy_name", clsids[1])
                        end
                    end
                    ## get profile from upstream_cluster
                    uc = event.get("upstream_cluster")
                    unless uc.nil?
                        ucIds = uc.split("@", -1)
                        if ucIds.length==3
                            event.set("waas_profile_orig", event.get("waas_profile"))
                            if ucIds[1].length() == 0
                                event.set("profileName", event.get("waas_profile"))
                            else
                                event.set("profileName", ucIds[1])
                            end
                        end
                    end
                    ################################# end of multi profile support ##############################
                else
                    event.set("pipline_error","missing messagejson in accesslog")
                end
            '
        }
        date {
            # set @timestamp to the start_time value from enforcer
            match => [ "start_time" ,"ISO8601" ]
        }
        mutate {
            #TODO remove_field => ["waas_profile_orig", "waas_protection_orig", "waas_classifier_orig", "waas_policy_orig"]
            remove_field => ["messagejson","message","start_time","ind"]
        }
    # Request Data log handling
    } else if [logtype] == "RequestData" {
        json {
            source => "message"
        }
        date {
            # set @timestamp to the start_time value from enforcer
            match => [ "start_time" ,"ISO8601" ]
        }
        mutate {
            remove_field => ["start_time", "message"]
        }
    } else if [logtype] == "Metric"{
        ruby {
            #Break the metric name into labels
            #scheme: envoy.statsd.metrics.http.lst-<profile name>.classifier.<classifier name>.protection.<protection name >@<namespace>/<profile name>.<metric name>
            #Some of the fields are currently not used by aggregation but are added for visibility
            #Assumes user can't use [@/] in names configurations
            #Assumes metric name (e.g. 'total_requests') won't include a dot
            code => "
                    metric_key = 'metric'
                    begin
                        cancel = false
                        err = nil
                        metric = event.get(metric_key)
                        if metric == nil
                            raise 'missing metric key'
                        end
                        #split the metric  by the '@' occurences'
                        splt = metric.split('@')
                        if splt.size != 2
                            msg = sprintf('expected 1 \'@\' delimiters, got %d', splt.size-1)
                            raise msg
                        end
                        #will start with the last section that includes the profile
                        s2 = splt[1] #<namespace>/<profile>.<metric name>
                        #string following last dot. assuming metric name(e.g. 'total_requests')will not include dots
                        indx = s2.rindex('.')
                        if indx == nil
                            msg = sprintf('last section %s is missing a dot delimiter', s2)
                            raise msg
                        end
                        #metric name
                        name = s2.slice(indx+1, s2.length-1)
                        nsprofile = s2.slice(0, indx)
                        nsp = nsprofile.split('/')
                        if nsp.size != 2
                            msg = sprintf('expected one \'/\' delimiter between namespace and profile for \'%s\'', nsprofile)
                            raise msg
                        end
                        namespace = nsprofile.split('/')[0]
                        profile = nsprofile.split('/')[1]
                    rescue RuntimeError => exception
                        err = 'failed to parse metric message: ' + exception.message
                        cancel = true
                    rescue StandardError => exception
                        err = 'unexpected error while parsing metric message: ' + exception.message
                        cancel = true
                    else
                        #now we have all we need for metric aggregation
                        #set profile name including the namespace prefix.
                        #'profile' string is used by logstash so will use profile_name as key
                        event.set('profile_name', nsprofile)
                        event.set('namespace', namespace)
                        event.set('name', name)
                        #set predefined
                        event.set('total_count', 1)
                        event.set('interval', 'minute')
                        #replace date to timestamp to match the time field in aggregation messages
                        event.set('@date', event.remove('@timestamp'))
                        #now we will try to parse the rest of the fields but won't drop the event on error
                        begin
                            s0 = splt[0].split('.protection.')[0] #prefix-<profile>.classifier.<classifier>
                            prefix = 'envoy.statsd.metrics.http.lst-'
                            s0 = s0.slice(prefix.length, s0.length-1)
                            classifier = s0.split('.classifier.')[1]
                            protection = splt[0].split('.protection.')[1]
                        rescue => exception
                            logger.debug('unexpected error while parsing extended metric message: ' + exception.message)
                            cancel = false
                        else
                            event.set('classifier', classifier)
                            # event.set('policy', policy)
                            event.set('protection', protection)
                        end
                    ensure
                        if err != nil
                            if metric != nil
                                err = sprintf('%s < %s >', err, metric)
                            end
                            logger.info(err)
                        end
                        event.remove(metric_key)
                        if cancel
                            logger.info('dropping metric log event')
                            event.cancel()
                        end
                    end
            "
        }
    }
}
output {
  {{- if (default .Values.global.elasticsearch.enabled true) }}
    if "Forensics" == [logtype] {
        elasticsearch {
            id => "forensics"
            ilm_enabled => true
            ilm_rollover_alias => "forensics"
            ilm_pattern => "{now/d}-000001"
            ilm_policy => "waas_ilm_security"
            hosts => ["${ES_SERVICE}"]
            user => "${ES_USER}"
            password => "${ES_PASSWORD}"
            ssl_enabled => true
          {{- with .Values.tls.clients.elasticsearch }}
            {{- if eq .verify true }}
            ssl_verification_mode => full
            ssl_certificate_authorities => {{ .ca | quote }}
            {{- else }}
            ssl_verification_mode => none
            {{- end }}
          {{- end }}
            manage_template => false
            template_overwrite => false
            sniffing => false
        }
    } else if "Access" == [logtype] {
        elasticsearch {
            id => "access"
            ilm_enabled => true
            ilm_rollover_alias => "access"
            ilm_pattern => "{now/d}-000001"
            ilm_policy => "waas_ilm_access"
            hosts => ["${ES_SERVICE}"]
            user => "${ES_USER}"
            password => "${ES_PASSWORD}"
            ssl_enabled => true
          {{- with .Values.tls.clients.elasticsearch }}
            {{- if eq .verify true }}
            ssl_verification_mode => full
            ssl_certificate_authorities => {{ .ca | quote }}
            {{- else }}
            ssl_verification_mode => none
            {{- end }}
          {{- end }}
            manage_template => false
            template_overwrite => false
            sniffing => false
        }
    } else if "RequestData" == [logtype] {
        elasticsearch {
            id => "request_data"
            ilm_enabled => true
            ilm_rollover_alias => "request_data"
            ilm_pattern => "{now/d}-000001"
            ilm_policy => "waas_ilm_request_data"
            hosts => ["${ES_SERVICE}"]
            user => "${ES_USER}"
            password => "${ES_PASSWORD}"
            ssl_enabled => true
          {{- with .Values.tls.clients.elasticsearch }}
            {{- if eq .verify true }}
            ssl_verification_mode => full
            ssl_certificate_authorities => {{ .ca | quote }}
            {{- else }}
            ssl_verification_mode => none
            {{- end }}
          {{- end }}
            manage_template => false
            template_overwrite => false
            sniffing => false
        }
    } else if "Metric" == [logtype] {
        elasticsearch {
            id => "metrics"
            ilm_enabled => true
            ilm_rollover_alias => "waas-metrics-enforcer"
            ilm_pattern => "{now/d}-000001"
            ilm_policy => "waas_ilm_metrics"
            hosts => ["${ES_SERVICE}"]
            user => "${ES_USER}"
            password => "${ES_PASSWORD}"
            ssl_enabled => true
          {{- with .Values.tls.clients.elasticsearch }}
            {{- if eq .verify true }}
            ssl_verification_mode => full
            ssl_certificate_authorities => {{ .ca | quote }}
            {{- else }}
            ssl_verification_mode => none
            {{- end }}
          {{- end }}
            manage_template => false
            template_overwrite => false
            sniffing => false
        }
    } else if "" in [pipline_error] {
  {{- else }}
    if "" in [pipline_error] {
  {{- end }}
         stdout { }
    }
    #DONT_REMOVE_REQUIRED_FOR_MULTI_PIPELINE
}
